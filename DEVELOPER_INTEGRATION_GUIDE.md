# üîå Developer Integration Guide

This guide explains how to connect your external applications (web apps, mobile apps, scripts) to the **AGATE Enterprise AI Platform**.

---

## üîó Endpoint Details

| Component | URL (Example) | Protocol | Auth Header |
| :--- | :--- | :--- | :--- |
| **Base URL** | `http://<server-ip>/v1` | OpenAI Standard | `Authorization: Bearer <NGINX_API_KEY>` |
| **Agent API** | `http://<server-ip>/api` | Custom Extended | `Authorization: Bearer <JWT_TOKEN>` |

---

## üíª Option 1: Standard OpenAI SDK (Recommended)
AGATE is 100% compatible with the standard OpenAI libraries. Use this for simple chat completions where you just want the model's answer.

### Python Example
```python
from openai import OpenAI

client = OpenAI(
    base_url="http://10.0.0.5:80/v1",  # Replace with your DevOps IP
    api_key="sk-tybo-production-key-12345"  # Your NGINX_API_KEY
)

response = client.chat.completions.create(
    model="internal-llm",  # Maps to Qwen2.5-7B
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Draft a summary for the Q3 financial report."}
    ],
    temperature=0.7
)

print(response.choices[0].message.content)
```

### Node.js Example
```javascript
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "http://10.0.0.5:80/v1",
  apiKey: "sk-tybo-production-key-12345"
});

const main = async () => {
  const completion = await openai.chat.completions.create({
    messages: [{ role: "user", content: "Explain Moroccan labor laws." }],
    model: "internal-llm",
  });

  console.log(completion.choices[0].message.content);
};

main();
```

---

## ü§ñ Option 2: Extended Agent API (Advanced)
Use this if you need the specialized **RAG capabilities**, **Knowledge Base Search**, or **Citations**.

*   **Endpoint**: `POST /agent/general`
*   **Auth**: Requires JWT Token (Login first at `/token`)

### Python Request (using requests)
```python
import requests

# 1. Login to get JWT
auth_resp = requests.post("http://10.0.0.5:8888/token", data={
    "username": "admin", 
    "password": "password123"
})
token = auth_resp.json()["access_token"]

# 2. Ask the Enterprise Agent
rag_resp = requests.post(
    "http://10.0.0.5:8888/agent/general",
    headers={"Authorization": f"Bearer {token}"},
    json={
        "question": "What is our policy on remote work?",
        "top_k": 3,
        "include_sources": True
    }
)

print(rag_resp.json()["answer"])
```

---

## üõ†Ô∏è Model Options

| Model Name | Description | Use Case |
| :--- | :--- | :--- |
| `internal-llm` | **Qwen2.5-7B** (Local CPU) | General chat, summarization, creative writing. Fast & Free. |
| `internal-embedding` | **BGE-M3** (Local CPU) | Text embeddings for vector search. |
| `high-reasoning-llm` | **DeepSeek-70B** (Cloud) | Complex logic, coding, math. (Requires Cloud API Key) |

---

## ‚ùì FAQ for Developers

**Q: Do I need to manage context/memory?**
A: Yes, the API is stateless. You must check the conversation history in your `messages` array for OpenAI calls.

**Q: How do I handle errors?**
A: Standard HTTP codes apply. 401 = Bad Key, 429 = Rate Limit, 500 = Server Error.

**Q: Can I stream responses?**
A: Yes! Use `stream=True` in the OpenAI SDK, just like standard ChatGPT.

---

**Generated by AGATE Enterprise Platform**
